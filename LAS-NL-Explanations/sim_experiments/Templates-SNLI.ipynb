{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0b757e40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import inflect\n",
    "\n",
    "inflect = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ded530cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_key', 'label', 'premise', 'hypothesis', 'explanation1',\n",
       "       'explanation2', 'explanation3', 'preds_NLI_t5-base_MT.RE_seed21',\n",
       "       'preds_NLI_t5-base_MT.RA_seed21', 't5-single-exp-seed21',\n",
       "       't5-MT-single-exp-seed21', 't5-MT-multi-exp-pred-seed21',\n",
       "       'preds_NLI_t5-base_ST.RE_seed21',\n",
       "       'preds_NLI_t5-base_sim.human_seed21_XE',\n",
       "       'label_probs_NLI_t5-base_sim.human_seed21_XE',\n",
       "       'preds_NLI_t5-base_sim.human_seed21_X',\n",
       "       'label_probs_NLI_t5-base_sim.human_seed21_X',\n",
       "       'preds_NLI_t5-base_sim.human_seed21_E',\n",
       "       'label_probs_NLI_t5-base_sim.human_seed21_E',\n",
       "       'preds_NLI_t5-base_sim.MT.RE_seed21_XE',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RE_seed21_XE',\n",
       "       'preds_NLI_t5-base_sim.MT.RE_seed21_X',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RE_seed21_X',\n",
       "       'preds_NLI_t5-base_sim.ST.RE_seed21_XE',\n",
       "       'label_probs_NLI_t5-base_sim.ST.RE_seed21_XE',\n",
       "       'preds_NLI_t5-base_sim.MT.RE_seed21_E',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RE_seed21_E',\n",
       "       'preds_NLI_t5-base_sim.ST.RE_seed21_X',\n",
       "       'label_probs_NLI_t5-base_sim.ST.RE_seed21_X',\n",
       "       'preds_NLI_t5-base_sim.ST.RE_seed21_E',\n",
       "       'label_probs_NLI_t5-base_sim.ST.RE_seed21_E',\n",
       "       'preds_NLI_t5-base_sim.MT.RA_seed21_XE',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RA_seed21_XE',\n",
       "       'preds_NLI_t5-base_sim.MT.RA_seed21_X',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RA_seed21_X',\n",
       "       'preds_NLI_t5-base_sim.MT.RA_seed21_E',\n",
       "       'label_probs_NLI_t5-base_sim.MT.RA_seed21_E', 't5-multi-exp-0-seed21',\n",
       "       't5-multi-exp-1-seed21', 't5-multi-exp-2-seed21',\n",
       "       'preds_NLI_t5-base_ST.RA_seed21', 't5-multi-exp-seed21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/test.tsv'\n",
    "df = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "df['t5-multi-exp-seed21'] = df.apply(lambda x: x[f't5-multi-exp-{x[\"preds_NLI_t5-base_ST.RA_seed21\"]}-seed21'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "61520d48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>explanation1</th>\n",
       "      <th>explanation2</th>\n",
       "      <th>explanation3</th>\n",
       "      <th>preds_NLI_t5-base_MT.RE_seed21</th>\n",
       "      <th>preds_NLI_t5-base_MT.RA_seed21</th>\n",
       "      <th>t5-single-exp-seed21</th>\n",
       "      <th>...</th>\n",
       "      <th>t5-multi-exp-1-seed21</th>\n",
       "      <th>t5-multi-exp-2-seed21</th>\n",
       "      <th>preds_NLI_t5-base_ST.RA_seed21</th>\n",
       "      <th>t5-multi-exp-seed21</th>\n",
       "      <th>premise_clean</th>\n",
       "      <th>hypo_clean</th>\n",
       "      <th>t5-MT-multi-exp-pred-seed21_clean</th>\n",
       "      <th>t5-MT-single-exp-seed21_clean</th>\n",
       "      <th>t5-single-exp-seed21_clean</th>\n",
       "      <th>t5-multi-exp-seed21_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>6337406386.jpg#2r1c</td>\n",
       "      <td>2</td>\n",
       "      <td>A girl wearing khakis and a red sweatshirt is ...</td>\n",
       "      <td>The girl is jumping in the air , while she is ...</td>\n",
       "      <td>The girl can be either in the forest or at the...</td>\n",
       "      <td>The girl can not be jumping in both a forest a...</td>\n",
       "      <td>There is n't a forest at the beach .</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The girl can not be in the forest and at the b...</td>\n",
       "      <td>...</td>\n",
       "      <td>The forest is at the beach.</td>\n",
       "      <td>The girl can not be in the forest and at the b...</td>\n",
       "      <td>2</td>\n",
       "      <td>The girl can not be in the forest and at the b...</td>\n",
       "      <td>a girl wearing khakis and a red sweatshirt is ...</td>\n",
       "      <td>the girl is jumping in the air while she is at...</td>\n",
       "      <td>the girl can not be in the forest and at the b...</td>\n",
       "      <td>the girl can not be in the forest and at the b...</td>\n",
       "      <td>the girl can not be in the forest and at the b...</td>\n",
       "      <td>the girl can not be in the forest and at the b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               unique_key  label  \\\n",
       "2131  6337406386.jpg#2r1c      2   \n",
       "\n",
       "                                                premise  \\\n",
       "2131  A girl wearing khakis and a red sweatshirt is ...   \n",
       "\n",
       "                                             hypothesis  \\\n",
       "2131  The girl is jumping in the air , while she is ...   \n",
       "\n",
       "                                           explanation1  \\\n",
       "2131  The girl can be either in the forest or at the...   \n",
       "\n",
       "                                           explanation2  \\\n",
       "2131  The girl can not be jumping in both a forest a...   \n",
       "\n",
       "                              explanation3  preds_NLI_t5-base_MT.RE_seed21  \\\n",
       "2131  There is n't a forest at the beach .                               2   \n",
       "\n",
       "      preds_NLI_t5-base_MT.RA_seed21  \\\n",
       "2131                               2   \n",
       "\n",
       "                                   t5-single-exp-seed21  ...  \\\n",
       "2131  The girl can not be in the forest and at the b...  ...   \n",
       "\n",
       "            t5-multi-exp-1-seed21  \\\n",
       "2131  The forest is at the beach.   \n",
       "\n",
       "                                  t5-multi-exp-2-seed21  \\\n",
       "2131  The girl can not be in the forest and at the b...   \n",
       "\n",
       "      preds_NLI_t5-base_ST.RA_seed21  \\\n",
       "2131                               2   \n",
       "\n",
       "                                    t5-multi-exp-seed21  \\\n",
       "2131  The girl can not be in the forest and at the b...   \n",
       "\n",
       "                                          premise_clean  \\\n",
       "2131  a girl wearing khakis and a red sweatshirt is ...   \n",
       "\n",
       "                                             hypo_clean  \\\n",
       "2131  the girl is jumping in the air while she is at...   \n",
       "\n",
       "                      t5-MT-multi-exp-pred-seed21_clean  \\\n",
       "2131  the girl can not be in the forest and at the b...   \n",
       "\n",
       "                          t5-MT-single-exp-seed21_clean  \\\n",
       "2131  the girl can not be in the forest and at the b...   \n",
       "\n",
       "                             t5-single-exp-seed21_clean  \\\n",
       "2131  the girl can not be in the forest and at the b...   \n",
       "\n",
       "                              t5-multi-exp-seed21_clean  \n",
       "2131  the girl can not be in the forest and at the b...  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_punct = [c for c in punctuation]\n",
    "custom_punct.remove(\"'\")\n",
    "print(custom_punct)\n",
    "def clean(x):\n",
    "    x = x.lower().strip()\n",
    "    x = ''.join([c for c in x if c not in custom_punct])\n",
    "    x = x.strip()\n",
    "    x = x.replace('  ', ' ')\n",
    "    return x\n",
    "# preprocess\n",
    "df['premise_clean'] = df.apply(lambda x: clean(x['premise']), axis=1)\n",
    "df['hypo_clean'] = df.apply(lambda x: clean(x['hypothesis']), axis=1)\n",
    "df['t5-MT-multi-exp-pred-seed21_clean'] = df.apply(lambda x: clean(x['t5-MT-multi-exp-pred-seed21']), axis=1)\n",
    "df['t5-MT-single-exp-seed21_clean'] = df.apply(lambda x: clean(x['t5-MT-single-exp-seed21']), axis=1)\n",
    "df['t5-single-exp-seed21_clean'] = df.apply(lambda x: clean(x['t5-single-exp-seed21']), axis=1)\n",
    "df['t5-multi-exp-seed21_clean'] = df.apply(lambda x: clean(x['t5-multi-exp-seed21']), axis=1)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a40f87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# General templates\n",
    "\"\\<premise\\>\" \n",
    "\n",
    "\"\\<hypothesis\\>\" \n",
    "\n",
    "\"\\<hypothesis\\> \\<premise\\>\" \n",
    "\n",
    "\"\\<premise\\> \\<hypothesis\\>\" \n",
    "\n",
    "\"Sentence 1 states \\<premise\\>. Sentence 2 is stating \\<hypothesis\\>\" \n",
    "\n",
    "\"Sentence 2 states <hypothesis>. Sentence 1 is stating \\<premise\\>\" \n",
    "    \n",
    "\"There is \\<hypothesis\\>\" \n",
    "    \n",
    "\"There is \\<premise\\>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "739b244c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-MT-single-exp-seed21_clean 1\n",
      "t5-MT-multi-exp-pred-seed21_clean 9\n",
      "t5-single-exp-seed21_clean 23\n",
      "t5-multi-exp-seed21_clean 12\n"
     ]
    }
   ],
   "source": [
    "explanations = ['t5-MT-single-exp-seed21_clean', 't5-MT-multi-exp-pred-seed21_clean', 't5-single-exp-seed21_clean', 't5-multi-exp-seed21_clean']\n",
    "predictions = ['preds_NLI_t5-base_MT.RE_seed21', 'preds_NLI_t5-base_MT.RA_seed21', 'preds_NLI_t5-base_ST.RE_seed21', 'preds_NLI_t5-base_ST.RA_seed21']\n",
    "\n",
    "for expl in explanations:\n",
    "    counter = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if row[expl] == row['hypo_clean']:\n",
    "            \n",
    "            counter += 1\n",
    "    print(expl, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cfc65887",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-MT-single-exp-seed21_clean 21\n",
      "t5-MT-multi-exp-pred-seed21_clean 57\n",
      "t5-single-exp-seed21_clean 89\n",
      "t5-multi-exp-seed21_clean 64\n"
     ]
    }
   ],
   "source": [
    "explanations = ['t5-MT-single-exp-seed21_clean', 't5-MT-multi-exp-pred-seed21_clean', 't5-single-exp-seed21_clean', 't5-multi-exp-seed21_clean']\n",
    "predictions = ['preds_NLI_t5-base_MT.RE_seed21', 'preds_NLI_t5-base_MT.RA_seed21', 'preds_NLI_t5-base_ST.RE_seed21', 'preds_NLI_t5-base_ST.RA_seed21']\n",
    "\n",
    "for expl in explanations:\n",
    "    counter = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if row[expl] == row['premise_clean'] or \\\n",
    "            row[expl] == row['hypo_clean'] or \\\n",
    "            row[expl] == row['hypo_clean'] + ' ' + row['premise_clean'] or \\\n",
    "            row[expl] == row['premise_clean'] + ' ' + row['hypo_clean'] or \\\n",
    "            row[expl] == 'there is ' + row['hypo_clean'] or \\\n",
    "            row[expl] == 'there is ' + row['premise_clean'] or \\\n",
    "            row[expl] == f\"sentence 1 states {row['premise_clean']}. sentence 2 is stating {row['hypo_clean']}.\" or \\\n",
    "            row[expl] == f\"sentence 1 states {row['hypo_clean']}. sentence 2 is stating {row['premise_clean']}.\":\n",
    "#             print(row[expl])\n",
    "            counter += 1\n",
    "    print(expl, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35622812",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "52cb9c08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "tuple_regex = OrderedDict()\n",
    "tuple_regex['contradiction', 'different than'] = r\"^(?P<s1>.*)\\ (is|are)\\ different than\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'is different'] = r'^(?P<s1>.*)\\ and\\ (?P<s2>.*) (is|are)\\ different'\n",
    "tuple_regex['contradiction', 'would not be able'] = r'^(?P<s1>.*)\\ would not be able to\\ (?P<s2>.*)'\n",
    "tuple_regex['contradiction', 'is not the same that'] = r\"^(?P<s1>.*)\\ (does not|doesnt|doesn't|dont|don't|do not)\\ (imply that|imply)\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'is not the same'] = r\"^(?P<s1>.*)\\ (is|are)\\ (not the same as|not|the opposite of)\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'cant at the same time'] = r\"(cant|can't|cannot|can not)\\ be\\ (?P<s1>.*)\\ and\\ (?P<s2>.*)\\ (simultaneously|at the same time|at once)\"\n",
    "tuple_regex['contradiction', 'cannot be'] = r\"^(?P<s1>.*)\\ (cant|can't|cannot|can not)\\ be\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'is not a'] = r\"^(?P<s1>.*)\\ (is|are)\\ not\\ (a|an)\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'is not'] = r\"^(?P<s1>.*)\\ (is|are)\\ not\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'cant be if'] = r\"^(cant|can't|cannot|can not)\\ be\\ (?P<s1>.*)\\ if\\ (is|are)\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'cant if'] = r\"^(cant|can't|cannot|can not)\\ (?P<s1>.*)\\ if\\ (?P<s2>.*)\"\n",
    "#     ('contradiction', 'cant be if he'): r\"(cant|can't|cannot|can not)\\ be\\ (?P<s1>.*)\\ if\\ (he|she|they)\\ (is|are)\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'does not mean'] = r\"^(just because)?\\ (?P<s1>.*)\\ (does not|doesn't|doesnt)\\ mean that\\ (?P<s2>.*)\"\n",
    "tuple_regex['contradiction', 'does not mean that'] = r\"^(just because)?\\ (?P<s1>.*)\\ (does not|doesn't|doesnt)\\ mean\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'no way to know A or B'] = r\"^no way to know\\ (?P<s1>.*)\\ or\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'there is more A than B'] = r\"^there is more\\ (?P<s1>.*)\\ than\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'can A without B'] = r\"^can\\ (?P<s1>.*)\\ without\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'could be A not just B'] = r\"^could be\\ (?P<s1>.*)\\ not just\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'there is not evidence A or B'] = r\"^there is no evidence\\ (?P<s1>.*)\\ or\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'A might not be B'] = r\"^(?P<s1>.*)\\ might not be\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'not everyone A will B'] = r\"^not\\ (everyone|every)\\ (?P<s1>.*)\\ will\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'we can’t tell if A is B'] = r\"^we\\ (can't|cannot|can not)\\ tell if\\ (?P<s1>.*)\\ (is|are)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'not all A are B'] = r\"^(not all|not every)\\ (?P<s1>.*)\\ (is|are)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'just because A does not mean B'] = r\"^just because\\ (?P<s1>.*)\\ (does not|doesnt|doesn't)\\ (necessarily mean|mean|necessarily make|make|necessarily imply|imply|necessarily indicate|indicate)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'A is not necessarily B'] = r\"^(?P<s1>.*)\\ (is|are)\\ not necessarily\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'A doe not have to be B'] = r\"^(?P<s1>.*)\\ (does not|doesnt|doesn't|don't|dont|do not)\\ have to be\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'A does not necessarily B'] = r\"^(?P<s1>.*)\\ (does not|doesnt|doesn't|don't|dont|do not)\\ necessarily\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'does not necessarily indicate that'] = r\"^(?P<s1>.*)\\ (does not|doesnt|doesn't|don't|dont|do not)\\ (necessarily mean|mean|necessarily make|make|imply|necessarily indicate|indicate) that\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'just does not necessarily indicate'] = r\"^just because\\ (?P<s1>.*)\\ (does not|doesnt|doesn't|don't|dont|do not)\\ (necessarily mean|mean|necessarily make|make|necessarily imply|imply|necessarily indicate|indicate)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'does not necessarily indicate'] = r\"(?P<s1>.*)\\ (does not|doesnt|doesn't|don't|dont|do not)\\ (necessarily mean|mean|necessarily make|make|necessarily imply|imply|necessarily indicate|indicate)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'we dont know A to B'] = r\"^we\\ (did not|didn't|didnt|dont|do not|don't)\\ know\\ (?P<s1>.*)\\ to\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'this does not imply A or B'] = r\"^this\\ (does not|doesnt|doesn't) imply\\ (?P<s1>.*)\\ or\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'A and B R1 two different'] = r\"^(?P<s1>.*)\\ and\\ (?P<s2>.*)\\ (is|are)\\ (two different|different)\"\n",
    "tuple_regex['neutral', 'not everyone A will B'] = r\"^not everyone\\ (?P<s1>.*)\\ (will|would)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'it cannot be assumed that A is B'] = r\"^it cannot be assumed that\\ (?P<s1>.*)\\ (is|are)\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'some A or B'] = r\"^some\\ (?P<s1>.*)\\ or\\ (?P<s2>.*)\"\n",
    "tuple_regex['neutral', 'does not have to be A to B'] = r\"^(does not|doesnt|doesn't|dont|don't|do not)\\ have to be\\ (?P<s1>.*)\\ (or|to)\\ (?P<s2>.*)\"\n",
    "tuple_regex['entailment', 'implies that'] = r'^(?P<s1>.*)\\ (implies that|implies|means|would imply)\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'if,then'] = r'^if (?P<s1>.*)\\ then\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'same as'] = r'^(?P<s1>.*)\\ (is|are)\\ (the same as|same as|a rephrasing of)\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'would be'] = r'^(?P<s1>.*)\\ would be\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'can also be said as'] = r'^(?P<s1>.*)\\ (can|could) also be said as\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'is the same thing'] = r'^(?P<s1>.*)\\ and\\ (?P<s2>.*)\\ (is|are)\\ the same thing'\n",
    "tuple_regex['entailment', 'so'] = r'^(?P<s1>.*)\\ (so|then)\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'synonyms'] = r'^(?P<s1>.*)\\ and\\ (?P<s2>.*)\\ are synonyms'\n",
    "tuple_regex['entailment', 'isatype'] = r'^(?P<s1>.*)\\ (is|are)\\ a type of\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'isaway'] = r'^(?P<s1>.*)\\ is a way of saying\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'is synonymous'] = r'^(?P<s1>.*)\\ (is|are)\\ synonymous with\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'is a form of'] = r'^(?P<s1>.*)\\ (is|are)\\ (a|another)\\ form of\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'isan'] = r'^(?P<s1>.*)\\ (is an|is a|are)\\ (?P<s2>.*)'\n",
    "tuple_regex['entailment', 'is/are'] = r'^(?P<s1>.*)\\ (is|are|have to be|has to be|must be)\\ (?P<s2>.*)'\n",
    "\n",
    "\n",
    "triple_regex = {\n",
    "    #NO Subject/VERB a man can not be reading the paper and climbing a mountain at the same time\n",
    "    ('contradiction', 'at the same time'): r'^(?P<s1>.*)\\ can not be\\ (?P<s2>.*)\\ and\\ (?P<s3>.*)\\ (at the same time|simultaneously)'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d4625bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def subject_verb(text):\n",
    "    doc=nlp(text)\n",
    "    sub_toks = [tok for tok in doc if (tok.dep_ in [\"nsubj\",'nsubjpass', 'expl']) or (tok.dep_ == 'ROOT' and tok.pos_=='NOUN')] #(woman, 'NOUN', 'ROOT')\n",
    "    verbs = [tok for tok in doc if tok.pos_ in ['VERB','AUX']]\n",
    "    if len(sub_toks) > 0 and len(verbs) > 0:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "db1a07ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-MT-single-exp-seed21_clean defaultdict(<function <lambda> at 0x137d92b80>, {'entailment': 876, 'contradiction': 1497, 'neutral': 242})\n",
      "t5-MT-multi-exp-pred-seed21_clean defaultdict(<function <lambda> at 0x28e4bcaf0>, {'contradiction': 1674, 'entailment': 886, 'neutral': 325})\n",
      "t5-single-exp-seed21_clean defaultdict(<function <lambda> at 0x16ddedee0>, {'contradiction': 1320, 'entailment': 758, 'neutral': 333})\n",
      "t5-multi-exp-seed21_clean defaultdict(<function <lambda> at 0x28e554ee0>, {'entailment': 737, 'contradiction': 1835, 'neutral': 124})\n"
     ]
    }
   ],
   "source": [
    "for expl, model_pred in zip(explanations, predictions):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    with open(f'snli_{expl}_patterns.tsv', 'w') as out:\n",
    "        out.write('unique_key\\tpremise\\thypothesis\\tpred_explanation\\tpattern\\tpred_label\\tlabel\\n')\n",
    "        for i, row in df.iterrows():\n",
    "            found = False\n",
    "            premise_tok = set([w.lower() for w in row['premise'].split(' ') if w not in punctuation])\n",
    "            hypo_tok = set([w.lower() for w in row['hypothesis'].split(' ') if w not in punctuation])\n",
    "            \n",
    "            for regex_name, regex in tuple_regex.items():\n",
    "                matches = re.search(regex, row[expl])\n",
    "                if matches:\n",
    "                    if subject_verb(matches.group('s1')) and subject_verb(matches.group('s2')):\n",
    "                        g1_tok = set([w.lower() for w in matches.group('s1').split(' ') if w not in punctuation])\n",
    "                        g2_tok = set([w.lower() for w in matches.group('s2').split(' ') if w not in punctuation])\n",
    "                        if len(g1_tok.intersection(premise_tok)) > len(g2_tok.intersection(premise_tok)):\n",
    "                            new_premise = matches.group('s1')\n",
    "                            new_hypothesis = matches.group('s2')\n",
    "                        else:\n",
    "                            new_premise = matches.group('s2')\n",
    "                            new_hypothesis = matches.group('s1')\n",
    "                        out.write(f\"{row['unique_key']}\\t{new_premise.capitalize()}.\\t{new_hypothesis.capitalize()}.\\t{row[expl.strip('_clean')]}\\t{regex_name[1]}\\t{row[model_pred]}\\t{row['label']}\\n\")\n",
    "                        count[regex_name[0]] += 1\n",
    "                        found = True\n",
    "                        break\n",
    "        print(expl, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "17333e12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-MT-single-exp-seed21_clean 1332\n",
      "t5-MT-multi-exp-pred-seed21_clean 1604\n",
      "t5-single-exp-seed21_clean 1590\n",
      "t5-multi-exp-seed21_clean 1637\n"
     ]
    }
   ],
   "source": [
    "for expl, model_pred in zip(explanations, predictions):\n",
    "    count = 0\n",
    "    with open(f'snli_{expl}_patterns.tsv', 'a') as out:\n",
    "        for i, row in df.iterrows():\n",
    "            found = False\n",
    "            for regex_name, regex in triple_regex.items():\n",
    "                matches = re.search(regex, row[expl])\n",
    "                if matches:\n",
    "                    \n",
    "                    doc=nlp(matches.group('s1'))\n",
    "                    plurals = [inflect.singular_noun(tok.text) for tok in doc]\n",
    "                    aux_verb = 'is'\n",
    "                    if any(w != False for w in plurals):\n",
    "                        aux_verb = 'are'\n",
    "                    s1 = matches.group('s1') + f' {aux_verb} ' + matches.group('s2')\n",
    "                    s2 = matches.group('s1') + f' {aux_verb} ' + matches.group('s3')\n",
    "                    if subject_verb(s1) and subject_verb(s2):\n",
    "                        out.write(f\"{row['unique_key']}\\t{s1}\\t{s2}\\t{row[expl].strip('_clean')}\\tcontr_triple\\t{row[model_pred]}\\t{row['label']}\\n\")\n",
    "                        \n",
    "                        count += 1\n",
    "                        found = True\n",
    "                        break\n",
    "    print(expl, count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare predictions and explanations on the original and the reconstructed input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/test.tsv'\n",
    "df = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "df['t5-multi-exp-seed21'] = df.apply(lambda x: x[f't5-multi-exp-{x[\"preds_NLI_t5-base_ST.RA_seed21\"]}-seed21'], axis=1)\n",
    "df.columns\n",
    "\n",
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/test_patterns.tsv'\n",
    "df_p = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "df_p.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49ff7d50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>explanation1</th>\n",
       "      <th>explanation2</th>\n",
       "      <th>explanation3</th>\n",
       "      <th>preds_NLI_t5-base_MT.RE_seed21</th>\n",
       "      <th>preds_NLI_t5-base_MT.RA_seed21</th>\n",
       "      <th>t5-single-exp-seed21</th>\n",
       "      <th>...</th>\n",
       "      <th>label_probs_NLI_t5-base_sim.MT.RA_seed21_XE</th>\n",
       "      <th>preds_NLI_t5-base_sim.MT.RA_seed21_X</th>\n",
       "      <th>label_probs_NLI_t5-base_sim.MT.RA_seed21_X</th>\n",
       "      <th>preds_NLI_t5-base_sim.MT.RA_seed21_E</th>\n",
       "      <th>label_probs_NLI_t5-base_sim.MT.RA_seed21_E</th>\n",
       "      <th>t5-multi-exp-0-seed21</th>\n",
       "      <th>t5-multi-exp-1-seed21</th>\n",
       "      <th>t5-multi-exp-2-seed21</th>\n",
       "      <th>preds_NLI_t5-base_ST.RA_seed21</th>\n",
       "      <th>orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>3411579899.jpg#4r1c</td>\n",
       "      <td>0</td>\n",
       "      <td>The cyclist rides on a wooded path .</td>\n",
       "      <td>The cyclist rides with a companion on a wooded...</td>\n",
       "      <td>A cyclist can ride without a companion .</td>\n",
       "      <td>Riding on a wooded path does not imply the cyc...</td>\n",
       "      <td>Just because the cyclist rides on a wooded pat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Not all cyclists ride with a companion.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355966</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351766</td>\n",
       "      <td>Not all cyclists ride with a companion.</td>\n",
       "      <td>The cyclist rides on a wooded path is the same...</td>\n",
       "      <td>The cyclist can not be riding with a companion.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               unique_key  label                               premise  \\\n",
       "4933  3411579899.jpg#4r1c      0  The cyclist rides on a wooded path .   \n",
       "\n",
       "                                             hypothesis  \\\n",
       "4933  The cyclist rides with a companion on a wooded...   \n",
       "\n",
       "                                  explanation1  \\\n",
       "4933  A cyclist can ride without a companion .   \n",
       "\n",
       "                                           explanation2  \\\n",
       "4933  Riding on a wooded path does not imply the cyc...   \n",
       "\n",
       "                                           explanation3  \\\n",
       "4933  Just because the cyclist rides on a wooded pat...   \n",
       "\n",
       "      preds_NLI_t5-base_MT.RE_seed21  preds_NLI_t5-base_MT.RA_seed21  \\\n",
       "4933                             NaN                               0   \n",
       "\n",
       "                         t5-single-exp-seed21  ...  \\\n",
       "4933  Not all cyclists ride with a companion.  ...   \n",
       "\n",
       "     label_probs_NLI_t5-base_sim.MT.RA_seed21_XE  \\\n",
       "4933                                    0.355966   \n",
       "\n",
       "     preds_NLI_t5-base_sim.MT.RA_seed21_X  \\\n",
       "4933                                    0   \n",
       "\n",
       "      label_probs_NLI_t5-base_sim.MT.RA_seed21_X  \\\n",
       "4933                                    0.339347   \n",
       "\n",
       "      preds_NLI_t5-base_sim.MT.RA_seed21_E  \\\n",
       "4933                                     0   \n",
       "\n",
       "      label_probs_NLI_t5-base_sim.MT.RA_seed21_E  \\\n",
       "4933                                    0.351766   \n",
       "\n",
       "                        t5-multi-exp-0-seed21  \\\n",
       "4933  Not all cyclists ride with a companion.   \n",
       "\n",
       "                                  t5-multi-exp-1-seed21  \\\n",
       "4933  The cyclist rides on a wooded path is the same...   \n",
       "\n",
       "                                t5-multi-exp-2-seed21  \\\n",
       "4933  The cyclist can not be riding with a companion.   \n",
       "\n",
       "      preds_NLI_t5-base_ST.RA_seed21  orig  \n",
       "4933                               0     0  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p['orig'] = df.apply(lambda x: df[df['unique_key']==row['unique_key']]['preds_NLI_t5-base_MT.RE_seed21'].values[0], axis=1) \n",
    "df_p.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a90ed4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.663274\n",
       "True     0.336726\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_p['orig'] == df['preds_NLI_t5-base_MT.RE_seed21']).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a01c205c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     0.923233\n",
      "False    0.076767\n",
      "dtype: float64\n",
      "True     3644\n",
      "False     303\n",
      "dtype: int64\n",
      "True     0.904226\n",
      "False    0.095774\n",
      "dtype: float64\n",
      "True     0.904226\n",
      "False    0.095774\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/snli_t5-MT-single-exp-seed21_clean_patterns.tsv'\n",
    "df_new = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "pred = 'preds_NLI_t5-base_MT.RE_seed21'\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts(normalize=True))\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts())\n",
    "df_change = df_new[df_new['pred_label'] == df_new[pred]]\n",
    "print((df_change['label']==df_change['pred_label']).value_counts(normalize=True))\n",
    "print((df_change['label']==df_change[pred]).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e1ffd6ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     0.903274\n",
      "False    0.096726\n",
      "dtype: float64\n",
      "True     3614\n",
      "False     387\n",
      "dtype: int64\n",
      "True     0.900111\n",
      "False    0.099889\n",
      "dtype: float64\n",
      "True     0.900111\n",
      "False    0.099889\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/snli_t5-single-exp-seed21_clean_patterns.tsv'\n",
    "df_new = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "pred = 'preds_NLI_t5-base_ST.RE_seed21'\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts(normalize=True))\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts())\n",
    "df_change = df_new[df_new['pred_label'] == df_new[pred]]\n",
    "print((df_change['label']==df_change['pred_label']).value_counts(normalize=True))\n",
    "print((df_change['label']==df_change[pred]).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a78adbd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     0.922254\n",
      "False    0.077746\n",
      "dtype: float64\n",
      "True     4140\n",
      "False     349\n",
      "dtype: int64\n",
      "True     0.891304\n",
      "False    0.108696\n",
      "dtype: float64\n",
      "True     0.891304\n",
      "False    0.108696\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/snli_t5-MT-multi-exp-pred-seed21_clean_patterns.tsv'\n",
    "df_new = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "pred = 'preds_NLI_t5-base_MT.RA_seed21'\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts(normalize=True))\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts())\n",
    "df_change = df_new[df_new['pred_label'] == df_new[pred]]\n",
    "print((df_change['label']==df_change['pred_label']).value_counts(normalize=True))\n",
    "print((df_change['label']==df_change[pred]).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d133b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "base_normal_path = 'LAS-NL-Explanations/sim_experiments/models/general/nli/snli_t5-multi-exp-seed21_clean_patterns.tsv'\n",
    "df_new = pd.read_csv(base_normal_path, delimiter = '\\t')\n",
    "pred = 'preds_NLI_t5-base_ST.RA_seed21'\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts(normalize=True))\n",
    "print((df_new['pred_label'] == df_new[pred]).value_counts())\n",
    "df_change = df_new[df_new['pred_label'] == df_new[pred]]\n",
    "print((df_change['label']==df_change['pred_label']).value_counts(normalize=True))\n",
    "print((df_change['label']==df_change[pred]).value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}